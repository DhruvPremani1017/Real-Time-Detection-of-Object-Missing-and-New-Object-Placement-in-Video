{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11601370,"sourceType":"datasetVersion","datasetId":7275971},{"sourceId":11799009,"sourceType":"datasetVersion","datasetId":7409501},{"sourceId":18802,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":15593,"modelId":23664}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install -q \"ultralytics>=8.3.117\" cython filterpy scikit-image \\\n               opencv-python-headless==4.10.0.84 tqdm","metadata":{"_uuid":"f473d048-6910-4c65-9e12-a6f6480c25ea","_cell_guid":"961a6b16-cb1b-4267-a875-2f45179957c1","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-13T16:36:25.168334Z","iopub.execute_input":"2025-05-13T16:36:25.168616Z","iopub.status.idle":"2025-05-13T16:45:09.028566Z","shell.execute_reply.started":"2025-05-13T16:36:25.168596Z","shell.execute_reply":"2025-05-13T16:45:09.027791Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:05\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0mm\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import sys, torch, ultralytics as ul\nprint(\"Py:\", sys.version)\nprint(\"Torch:\", torch.__version__)\nprint(\"Ultralytics:\", ul.__version__)\n\nfrom ultralytics import YOLO\nimport cv2, torch, time, pathlib, collections, numpy as np","metadata":{"_uuid":"c076fda2-94cc-4df9-a022-2711ff7b1015","_cell_guid":"861294a8-4d98-45d0-bdc2-c89689d1e17b","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-13T16:45:55.587805Z","iopub.execute_input":"2025-05-13T16:45:55.588389Z","iopub.status.idle":"2025-05-13T16:45:55.727025Z","shell.execute_reply.started":"2025-05-13T16:45:55.588362Z","shell.execute_reply":"2025-05-13T16:45:55.726341Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file ✅ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\nPy: 3.11.11 (main, Dec  4 2024, 08:55:07) [GCC 11.4.0]\nTorch: 2.5.1+cu124\nUltralytics: 8.3.133\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import cv2\nimport time\nimport torch\nfrom ultralytics import YOLO\n\n# ───── CONFIG ─────\nINPUT_VIDEO  = \"/kaggle/input/video1/WhatsApp Video 2025-05-13 at 22.03.19.mp4\"  # your 20 s clip\nOUTPUT_VIDEO = \"output_with_counts.mp4\"\nMISS_TOL     = 30   # frames tolerance before declaring MISSING (~1 s @ 30 FPS)\n\n# choose GPU if available\nDEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n\n# ───── MODEL LOADING ─────\nmodel = YOLO(\"yolov8n.pt\")\nmodel.fuse()          # in-place fuse Conv+BN\nmodel.to(DEVICE)\nif DEVICE.startswith(\"cuda\"):\n    model.model.half()\n\n# ───── INVENTORY FOR NEW / MISSING EVENTS ─────\nclass LiveInventory:\n    def __init__(self, miss_tolerance=30):\n        self.last_seen = {}     # id → last frame index\n        self.frame_idx = 0\n        self.miss_tol  = miss_tolerance\n\n    def update(self, tracks):\n        current = {int(t.id) for t in tracks if t.id is not None}\n\n        # NEW = seen this frame but never before\n        new_ids = [i for i in current if i not in self.last_seen]\n\n        # refresh timestamps\n        for i in current:\n            self.last_seen[i] = self.frame_idx\n\n        # MISSING = dropped out beyond tolerance\n        missing = [i for i, last in list(self.last_seen.items())\n                   if self.frame_idx - last > self.miss_tol]\n        for i in missing:\n            del self.last_seen[i]\n\n        self.frame_idx += 1\n        return new_ids, missing\n\n# ───── PROCESSING LOOP ─────\ncap = cv2.VideoCapture(INPUT_VIDEO)\nfps_in = cap.get(cv2.CAP_PROP_FPS) or 25\nw, h   = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\nout    = cv2.VideoWriter(OUTPUT_VIDEO, fourcc, fps_in, (w, h))\n\ninv         = LiveInventory(miss_tolerance=MISS_TOL)\nentered_cnt = 0\nexited_cnt  = 0\nstart       = time.time()\nframe_count = 0\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # track with YOLOv8 + ByteTrack\n    results = model.track(\n        frame,\n        tracker=\"bytetrack.yaml\",\n        persist=True,\n        device=DEVICE,\n        imgsz=640,\n        verbose=False\n    )\n    tracks = results[0].boxes\n\n    # compute events\n    new_ids, missing_ids = inv.update(tracks)\n    entered_cnt += len(new_ids)\n    exited_cnt  += len(missing_ids)\n\n    # draw boxes+IDs\n    vis = results[0].plot()\n\n    # overlay the running counters\n    text = f\"Entered: {entered_cnt}   Exited: {exited_cnt}\"\n    cv2.putText(vis, text, (10, 30),\n                cv2.FONT_HERSHEY_SIMPLEX, 0.8,\n                (0, 255, 0), 2, cv2.LINE_AA)\n\n    # (optional) also draw latest event IDs below\n    evt_text = f\"New IDs: {new_ids}  Missing IDs: {missing_ids}\"\n    cv2.putText(vis, evt_text, (10, 60),\n                cv2.FONT_HERSHEY_SIMPLEX, 0.6,\n                (200, 200, 200), 1, cv2.LINE_AA)\n\n    out.write(vis)\n    frame_count += 1\n\n# cleanup\ncap.release()\nout.release()\nelapsed = time.time() - start\nprint(f\"Processed {frame_count} frames in {elapsed:.1f}s → {frame_count/elapsed:.2f} FPS\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T17:13:46.704379Z","iopub.execute_input":"2025-05-13T17:13:46.705041Z","iopub.status.idle":"2025-05-13T17:14:07.466621Z","shell.execute_reply.started":"2025-05-13T17:13:46.705010Z","shell.execute_reply":"2025-05-13T17:14:07.465812Z"}},"outputs":[{"name":"stdout","text":"YOLOv8n summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\nProcessed 1239 frames in 20.6s → 60.22 FPS\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import zipfile\nfrom IPython.display import FileLink, display\n\n# Create a zip archive containing your output video\nwith zipfile.ZipFile('outputnew.zip', 'w', compression=zipfile.ZIP_DEFLATED) as zipf:\n    zipf.write('/kaggle/working/output_with_counts.mp4')\n\n# Display a download link for the zip file\ndisplay(FileLink('outputnew.zip'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T17:15:12.271655Z","iopub.execute_input":"2025-05-13T17:15:12.272506Z","iopub.status.idle":"2025-05-13T17:15:13.231793Z","shell.execute_reply.started":"2025-05-13T17:15:12.272469Z","shell.execute_reply":"2025-05-13T17:15:13.231159Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"/kaggle/working/outputnew.zip","text/html":"<a href='outputnew.zip' target='_blank'>outputnew.zip</a><br>"},"metadata":{}}],"execution_count":5}]}